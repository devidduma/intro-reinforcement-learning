Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
dense (Dense)                (None, 30)                150
_________________________________________________________________
dense_1 (Dense)              (None, 60)                1860
_________________________________________________________________
dense_2 (Dense)              (None, 60)                3660
_________________________________________________________________
dense_3 (Dense)              (None, 30)                1830
_________________________________________________________________
dense_4 (Dense)              (None, 2)                 62
=================================================================
Total params: 7,562
Trainable params: 7,562
Non-trainable params: 0
_________________________________________________________________
2021-06-25 13:42:35.262374: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
episode: 0 	score: 21.05 	global_step: 1263 	epsilon: 0.9962181635409519 	learning_rate_decay: 0.01
episode: 1 	score: 23.116666666666667 	global_step: 2650 	epsilon: 0.9920815058423313 	learning_rate_decay: 0.01
episode: 2 	score: 24.416666666666668 	global_step: 4115 	epsilon: 0.987730868626606 	learning_rate_decay: 0.01
episode: 3 	score: 21.366666666666667 	global_step: 5397 	epsilon: 0.9839393457906263 	learning_rate_decay: 0.01
episode: 4 	score: 22.683333333333334 	global_step: 6758 	epsilon: 0.9799301058610554 	learning_rate_decay: 0.01
episode: 5 	score: 23.283333333333335 	global_step: 8155 	epsilon: 0.9758318066247375 	learning_rate_decay: 0.01
episode: 6 	score: 26.2 	global_step: 9727 	epsilon: 0.9712406114853488 	learning_rate_decay: 0.01
episode: 7 	score: 23.716666666666665 	global_step: 11150 	epsilon: 0.9671293288400938 	learning_rate_decay: 0.01
episode: 8 	score: 23.733333333333334 	global_step: 12574 	epsilon: 0.9630065586702977 	learning_rate_decay: 0.01
episode: 9 	score: 25.1 	global_step: 14080 	epsilon: 0.9586655023571486 	learning_rate_decay: 0.01
episode: 10 	score: 25.083333333333332 	global_step: 15585 	epsilon: 0.9543468777674655 	learning_rate_decay: 0.01
episode: 11 	score: 23.933333333333334 	global_step: 17021 	epsilon: 0.950244388371302 	learning_rate_decay: 0.01
episode: 12 	score: 27.566666666666666 	global_step: 18675 	epsilon: 0.9455409475482286 	learning_rate_decay: 0.01
episode: 13 	score: 25.433333333333334 	global_step: 20201 	epsilon: 0.9412221478874322 	learning_rate_decay: 0.01
episode: 14 	score: 27.183333333333334 	global_step: 21832 	epsilon: 0.9366279898002859 	learning_rate_decay: 0.01
episode: 15 	score: 23.816666666666666 	global_step: 23261 	epsilon: 0.932621254172205 	learning_rate_decay: 0.01
episode: 16 	score: 22.7 	global_step: 24623 	epsilon: 0.9288183326828525 	learning_rate_decay: 0.01
episode: 17 	score: 25.583333333333332 	global_step: 26158 	epsilon: 0.9245509510472162 	learning_rate_decay: 0.01
episode: 18 	score: 24.966666666666665 	global_step: 27656 	epsilon: 0.9204053350310951 	learning_rate_decay: 0.01
episode: 19 	score: 28.25 	global_step: 29351 	epsilon: 0.9157369463374766 	learning_rate_decay: 0.01
episode: 20 	score: 26.816666666666666 	global_step: 30960 	epsilon: 0.9113273286573755 	learning_rate_decay: 0.01
episode: 21 	score: 23.066666666666666 	global_step: 32344 	epsilon: 0.9075513363095102 	learning_rate_decay: 0.01
episode: 22 	score: 27.4 	global_step: 33988 	epsilon: 0.9030863062363402 	learning_rate_decay: 0.01
episode: 23 	score: 30.083333333333332 	global_step: 35793 	epsilon: 0.8982093029759918 	learning_rate_decay: 0.01
episode: 24 	score: 29.3 	global_step: 37551 	epsilon: 0.893484609991977 	learning_rate_decay: 0.01
episode: 25 	score: 26.733333333333334 	global_step: 39155 	epsilon: 0.8891954835296647 	learning_rate_decay: 0.01
episode: 26 	score: 27.666666666666668 	global_step: 40815 	epsilon: 0.8847782913335229 	learning_rate_decay: 0.01
episode: 27 	score: 33.2 	global_step: 42807 	epsilon: 0.8795066158122706 	learning_rate_decay: 0.01
episode: 28 	score: 28.116666666666667 	global_step: 44494 	epsilon: 0.8750666709272623 	learning_rate_decay: 0.01
episode: 29 	score: 30.2 	global_step: 46306 	epsilon: 0.8703227071637608 	learning_rate_decay: 0.01
episode: 30 	score: 32.666666666666664 	global_step: 48266 	epsilon: 0.8652202180113581 	learning_rate_decay: 0.01
episode: 31 	score: 28.35 	global_step: 49967 	epsilon: 0.8608162389423742 	learning_rate_decay: 0.01
episode: 32 	score: 35.21666666666667 	global_step: 52080 	epsilon: 0.8553767752392475 	learning_rate_decay: 0.01
episode: 33 	score: 33.71666666666667 	global_step: 54103 	epsilon: 0.8502012069747927 	learning_rate_decay: 0.01
episode: 34 	score: 35.983333333333334 	global_step: 56262 	epsilon: 0.8447122407302184 	learning_rate_decay: 0.01
episode: 35 	score: 33.03333333333333 	global_step: 58244 	epsilon: 0.8397044770706916 	learning_rate_decay: 0.01
episode: 36 	score: 28.666666666666668 	global_step: 59965 	epsilon: 0.8353802489698748 	learning_rate_decay: 0.01
episode: 37 	score: 31.15 	global_step: 61834 	epsilon: 0.8307093719484571 	learning_rate_decay: 0.01
episode: 38 	score: 29.866666666666667 	global_step: 63626 	epsilon: 0.8262554545410496 	learning_rate_decay: 0.01
episode: 39 	score: 34.86666666666667 	global_step: 65718 	epsilon: 0.8210861059378973 	learning_rate_decay: 0.01
episode: 40 	score: 41.733333333333334 	global_step: 68222 	epsilon: 0.8149412070295686 	learning_rate_decay: 0.01
episode: 41 	score: 31.683333333333334 	global_step: 70123 	epsilon: 0.8103068178957777 	learning_rate_decay: 0.01
episode: 42 	score: 30.183333333333334 	global_step: 71934 	epsilon: 0.8059163518690852 	learning_rate_decay: 0.01
episode: 43 	score: 40.63333333333333 	global_step: 74372 	epsilon: 0.8000433745213128 	learning_rate_decay: 0.01
episode: 44 	score: 46.3 	global_step: 77150 	epsilon: 0.7934035098257928 	learning_rate_decay: 0.01
episode: 45 	score: 39.06666666666667 	global_step: 79494 	epsilon: 0.7878438586487599 	learning_rate_decay: 0.01
episode: 46 	score: 47.43333333333333 	global_step: 82340 	epsilon: 0.7811458721299879 	learning_rate_decay: 0.01
episode: 47 	score: 44.06666666666667 	global_step: 84986 	epsilon: 0.7749696726994679 	learning_rate_decay: 0.01
episode: 48 	score: 41.3 	global_step: 87464 	epsilon: 0.7692299007092398 	learning_rate_decay: 0.01
episode: 49 	score: 49.81666666666667 	global_step: 90453 	epsilon: 0.7623630394737219 	learning_rate_decay: 0.01
episode: 50 	score: 49.95 	global_step: 93450 	epsilon: 0.7555393450365374 	learning_rate_decay: 0.01
episode: 51 	score: 39.5 	global_step: 95820 	epsilon: 0.7501865041632043 	learning_rate_decay: 0.01
episode: 52 	score: 44.06666666666667 	global_step: 98464 	epsilon: 0.7442595532843114 	learning_rate_decay: 0.01
episode: 53 	score: 42.28333333333333 	global_step: 101001 	epsilon: 0.7386164872880154 	learning_rate_decay: 0.01
episode: 54 	score: 47.65 	global_step: 103860 	epsilon: 0.7323084548823587 	learning_rate_decay: 0.01
episode: 55 	score: 45.583333333333336 	global_step: 106595 	epsilon: 0.7263244380345429 	learning_rate_decay: 0.01
episode: 56 	score: 44.95 	global_step: 109292 	epsilon: 0.7204714484265845 	learning_rate_decay: 0.01
episode: 57 	score: 51.36666666666667 	global_step: 112374 	epsilon: 0.7138406608373473 	learning_rate_decay: 0.01
episode: 58 	score: 57.56666666666667 	global_step: 115828 	epsilon: 0.7064820238123061 	learning_rate_decay: 0.01
episode: 59 	score: 57.71666666666667 	global_step: 119291 	epsilon: 0.6991803652529943 	learning_rate_decay: 0.01
episode: 60 	score: 60.833333333333336 	global_step: 122943 	epsilon: 0.6915619436629022 	learning_rate_decay: 0.01
episode: 61 	score: 52.7 	global_step: 126105 	epsilon: 0.6850327939885682 	learning_rate_decay: 0.01
episode: 62 	score: 56.166666666666664 	global_step: 129475 	epsilon: 0.678141993793764 	learning_rate_decay: 0.01
episode: 63 	score: 61.766666666666666 	global_step: 133181 	epsilon: 0.670644157565532 	learning_rate_decay: 0.01
episode: 64 	score: 70.6 	global_step: 137417 	epsilon: 0.6621755225837992 	learning_rate_decay: 0.01
episode: 65 	score: 70.16666666666667 	global_step: 141632 	epsilon: 0.6538550178788697 	learning_rate_decay: 0.01
episode: 66 	score: 63.3 	global_step: 145430 	epsilon: 0.6464472648043327 	learning_rate_decay: 0.01
episode: 67 	score: 76.23333333333333 	global_step: 150004 	epsilon: 0.6376372857263354 	learning_rate_decay: 0.01
episode: 68 	score: 70.16666666666667 	global_step: 154215 	epsilon: 0.6296326695036552 	learning_rate_decay: 0.01
episode: 69 	score: 91.51666666666667 	global_step: 159708 	epsilon: 0.6193419604797658 	learning_rate_decay: 0.01
episode: 70 	score: 80.15 	global_step: 164517 	epsilon: 0.6104708463589635 	learning_rate_decay: 0.01
episode: 71 	score: 90.2 	global_step: 169930 	epsilon: 0.6006374538577076 	learning_rate_decay: 0.01
episode: 72 	score: 97.63333333333334 	global_step: 175788 	epsilon: 0.5901740468033783 	learning_rate_decay: 0.01
episode: 73 	score: 95.01666666666667 	global_step: 181489 	epsilon: 0.5801661118776993 	learning_rate_decay: 0.01
episode: 74 	score: 95.9 	global_step: 187243 	epsilon: 0.5702372124397248 	learning_rate_decay: 0.01
episode: 75 	score: 110.26666666666667 	global_step: 193859 	epsilon: 0.5590307086728138 	learning_rate_decay: 0.01
episode: 76 	score: 116.36666666666666 	global_step: 200841 	epsilon: 0.5474430156346854 	learning_rate_decay: 0.01
episode: 77 	score: 112.01666666666667 	global_step: 207562 	epsilon: 0.5365154422621228 	learning_rate_decay: 0.01
episode: 78 	score: 141.13333333333333 	global_step: 216031 	epsilon: 0.5230558817809439 	learning_rate_decay: 0.01
episode: 79 	score: 144.31666666666666 	global_step: 224690 	epsilon: 0.5096434012508653 	learning_rate_decay: 0.01
episode: 80 	score: 155.38333333333333 	global_step: 234013 	epsilon: 0.4955866567507165 	learning_rate_decay: 0.01
episode: 81 	score: 169.5 	global_step: 244183 	epsilon: 0.4806946187393152 	learning_rate_decay: 0.01
episode: 82 	score: 161.83333333333334 	global_step: 253893 	epsilon: 0.4668939464618897 	learning_rate_decay: 0.01
episode: 83 	score: 163.85 	global_step: 263724 	epsilon: 0.45332490241215573 	learning_rate_decay: 0.01
episode: 84 	score: 175.15 	global_step: 274233 	epsilon: 0.439255849931476 	learning_rate_decay: 0.01
episode: 85 	score: 190.18333333333334 	global_step: 285644 	epsilon: 0.4244732521968286 	learning_rate_decay: 0.01
episode: 86 	score: 204.93333333333334 	global_step: 297940 	epsilon: 0.40910053729674106 	learning_rate_decay: 0.01
episode: 87 	score: 213.71666666666667 	global_step: 310765 	epsilon: 0.3936593260547347 	learning_rate_decay: 0.01
episode: 88 	score: 236.18333333333334 	global_step: 324936 	epsilon: 0.3772744160961398 	learning_rate_decay: 0.01
episode: 89 	score: 244.96666666666667 	global_step: 339634 	epsilon: 0.3610002860356194 	learning_rate_decay: 0.01
episode: 90 	score: 255.85 	global_step: 354986 	epsilon: 0.3447510911071516 	learning_rate_decay: 0.01
episode: 91 	score: 287.01666666666665 	global_step: 372207 	epsilon: 0.32739244996803635 	learning_rate_decay: 0.01
episode: 92 	score: 247.88333333333333 	global_step: 387080 	epsilon: 0.3131056073068872 	learning_rate_decay: 0.01
episode: 93 	score: 268.15 	global_step: 403169 	epsilon: 0.2983518410639894 	learning_rate_decay: 0.01
episode: 94 	score: 306.8333333333333 	global_step: 421579 	epsilon: 0.2823206218265192 	learning_rate_decay: 0.01
episode: 95 	score: 277.75 	global_step: 438244 	epsilon: 0.26855300524709935 	learning_rate_decay: 0.01
episode: 96 	score: 296.23333333333335 	global_step: 456018 	epsilon: 0.2546082850289822 	learning_rate_decay: 0.01
episode: 97 	score: 293.8333333333333 	global_step: 473648 	epsilon: 0.24149195203104368 	learning_rate_decay: 0.01
episode: 98 	score: 301.3 	global_step: 491726 	epsilon: 0.2287436779195202 	learning_rate_decay: 0.01
episode: 99 	score: 311.93333333333334 	global_step: 510442 	epsilon: 0.216254073373041 	learning_rate_decay: 0.01
episode: 100 	score: 323.8333333333333 	global_step: 529872 	epsilon: 0.20400895595219679 	learning_rate_decay: 0.01
episode: 101 	score: 316.95 	global_step: 548889 	epsilon: 0.19269580566239097 	learning_rate_decay: 0.01
